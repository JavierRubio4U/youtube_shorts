# scripts/ai_narration.py
import json
import re
import subprocess
from pathlib import Path
import logging
import logging
import ollama

from moviepy.editor import AudioFileClip

import ollama
from langdetect import detect, DetectorFactory

import warnings
warnings.filterwarnings("ignore", message=".*torch.load.*weights_only.*")

# Para resultados consistentes
DetectorFactory.seed = 0

# --- Rutas y dirs ---
ROOT = Path(__file__).resolve().parents[1]
STATE = ROOT / "output" / "state"
STATE.mkdir(parents=True, exist_ok=True)

# --- Logging ---
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

# --- Funciones de texto ---
def _normalize_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def _sentences(s: str):
    return [seg.strip() for seg in re.split(r"(?<=[\.\!\?‚Ä¶])\s+", s) if seg.strip()]

def _trim_to_words(text: str, max_words: int) -> str:
    words = text.split()
    if len(words) <= max_words:
        return text
    t = " ".join(words[:max_words])
    return t.rstrip(",;:") + "‚Ä¶"

# --- Funciones de IA ---
def _generate_narration_with_ai(sel: dict, model='mistral', max_words=60, min_words=50) -> str | None:
    """
    Genera una sinopsis con Ollama, con un intento de auto-correcci√≥n si excede la longitud.
    """
    initial_prompt = f"""
    Genera una sinopsis detallada y atractiva de entre {min_words} y {max_words} palabras en espa√±ol para la pel√≠cula '{sel.get("titulo")}'.
    Es crucial que la sinopsis finalice con una oraci√≥n completa y natural.
    NO excedas las {max_words} palabras.
    El t√≠tulo '{sel.get("titulo")}' es un nombre propio y NO debe traducirse.
    La sinopsis debe ser un p√°rrafo cohesivo y no debe listar metadata como reparto o g√©neros.
    Usa la siguiente informaci√≥n para inspirarte:

    T√≠tulo: {sel.get("titulo")}
    Sinopsis original: {sel.get("sinopsis")}
    G√©neros: {', '.join(sel.get("generos"))}
    """
    
    try:
        # --- Primer Intento ---
        logging.info("Generando sinopsis (Intento 1)...")
        response = ollama.chat(model=model, messages=[{'role': 'user', 'content': initial_prompt}])
        generated_text = response['message']['content'].strip()
        word_count = len(generated_text.split())

        # Si el primer intento es demasiado largo, lo corregimos
        if word_count > max_words:
            logging.warning(
                f"Intento 1 gener√≥ {word_count} palabras (m√°ximo {max_words}). Pidiendo a la IA que lo resuma."
            )
            
            # --- Segundo Intento (Auto-Correcci√≥n) ---
            refinement_prompt = f"""
            El siguiente texto es demasiado largo. Resume este texto para que tenga menos de {max_words} palabras.
            El resultado DEBE ser una frase completa y sonar natural. No lo cortes.
            Simplemente devuelve el texto corregido, sin a√±adir introducciones como 'Aqu√≠ tienes el resumen:'.

            Texto a corregir:
            "{generated_text}"
            """
            response = ollama.chat(model=model, messages=[{'role': 'user', 'content': refinement_prompt}])
            generated_text = response['message']['content'].strip()
            word_count = len(generated_text.split())

        # Verificaci√≥n final
        if word_count > max_words or word_count < min_words:
            logging.warning(f"La narraci√≥n final tiene {word_count} palabras, fuera del rango deseado ({min_words}-{max_words}).")
        else:
            logging.info(f"Narraci√≥n generada con √©xito ({word_count} palabras).")
            
        return generated_text

    except Exception as e:
        logging.error(f"Error al generar narraci√≥n con Ollama: {e}")
        return None
    
def generate_narration(sel: dict, tmdb_id: str, slug: str, tmpdir=None) -> tuple[str | None, Path | None]:
    """
    Genera la narraci√≥n con IA (usando auto-correcci√≥n) y sintetiza el audio.
    """
    logging.info("üîé Generando sinopsis con IA local...")
    # La funci√≥n de generaci√≥n ahora se encarga de la longitud.
    narracion = _generate_narration_with_ai(sel)
    
    # Ya no necesitamos el log de "recortada" porque no se recorta.
    logging.info(f"Narraci√≥n generada: {narracion[:100]}...") if narracion else logging.warning("No se gener√≥ narraci√≥n.")

    voice_path = None
    if narracion:
        # ¬°¬°¬° LA L√çNEA DE _trim_to_words HA SIDO ELIMINADA !!!
        
        voice_path = (tmpdir / f"{tmdb_id}_{slug}_narracion.wav") if tmpdir else (STATE / f"{tmdb_id}_{slug}_narracion.wav")
        if not voice_path.exists():
            voice_path = _synthesize_xtts_with_pauses(narracion, voice_path, tmpdir) or _synthesize_tts_coqui(narracion, voice_path)
        
        if voice_path:
            # Este log sigue siendo √∫til para saber la duraci√≥n final del audio
            audio_duration = AudioFileClip(str(voice_path)).duration
            logging.info(f"Audio de voz generado con duraci√≥n de {audio_duration:.2f} segundos.")
        else:
            logging.warning("No se pudo generar el audio de voz. El v√≠deo no tendr√° narraci√≥n.")

    return narracion, voice_path

# --- Funciones de audio ---
def _clean_for_tts(text: str) -> str:
    if not text: return ""
    text = re.sub(r"http[s]?://\S+", "", text)
    text = re.sub(r"\s+", " ", text).replace("‚Äî","-").replace("‚Äì","-")
    text = re.sub(r"[^A-Za-z√Å√â√ç√ì√ö√ú√ë√°√©√≠√≥√∫√º√±0-9 ,\.\-\!\?\:\;\'\"]+", " ", text)
    return re.sub(r"\s+", " ", text).strip()[:900]


def _concat_wav_ffmpeg(inputs: list[Path], out_wav: Path) -> bool:
    if not inputs: return False
    cmd = ["ffmpeg", "-y", "-hide_banner", "-loglevel", "error"]
    for s in inputs: cmd += ["-i", str(s)]
    n = len(inputs)
    filt = "".join(f"[{i}:a]" for i in range(n)) + f"concat=n={n}:v=0:a=1[outa]"
    cmd += ["-filter_complex", filt, "-map", "[outa]", str(out_wav)]
    res = subprocess.run(cmd, check=True, capture_output=True)
    return res.returncode == 0 and out_wav.exists() and out_wav.stat().st_size > 0

def _synthesize_tts_coqui(text: str, out_wav: Path) -> Path | None:
    try:
        from TTS.api import TTS
    except ImportError:
        logging.error("Coqui TTS no est√° instalado. No se generar√° audio de voz.")
        return None
    try:
        cleaned_text = _clean_for_tts(text)
        if not cleaned_text:
            return None
        tts = TTS(model_name="tts_models/es/css10/vits", progress_bar=False, gpu=False)
        tts.tts_to_file(text=cleaned_text, file_path=str(out_wav), language="es")
        if out_wav.exists() and out_wav.stat().st_size > 0:
            return out_wav
    except Exception as e:
        logging.error(f"Error en la s√≠ntesis de voz con VITS: {e}")
    return None

def _synthesize_xtts_with_pauses(text: str, out_wav: Path, tmpdir=None) -> Path | None:
    try:
        from TTS.api import TTS
    except ImportError:
        logging.error("Coqui TTS no est√° instalado. No se generar√° audio de voz.")
        return None

    cleaned_text = _clean_for_tts(text)
    if not cleaned_text:
        return None
    
    sents = _sentences(cleaned_text) or [cleaned_text]
    
    try:
        tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2", progress_bar=False, gpu=False)
        
        tmp_parts = []
        for i, s in enumerate(sents, 1):
            part_path = (tmpdir / f"_xtts_part_{i}.wav") if tmpdir else (STATE / f"_xtts_part_{i}.wav")
            tts.tts_to_file(text=s, file_path=str(part_path), language="es", speaker="Alma Mar√≠a")
            if not part_path.exists(): raise FileNotFoundError
            tmp_parts.append(part_path)
        
        silence_path = (tmpdir / "_xtts_silence.wav") if tmpdir else (STATE / "_xtts_silence.wav")
        subprocess.run(["ffmpeg", "-y", "-f", "lavfi", "-i", "anullsrc=r=44100:cl=mono", "-t", "0.35", "-q:a", "9", str(silence_path)], check=True, capture_output=True)
        
        seq = []
        for i, p in enumerate(tmp_parts):
            seq.append(p)
            if i < len(tmp_parts) - 1:
                seq.append(silence_path)
        
        if _concat_wav_ffmpeg(seq, out_wav):
            for p in set(tmp_parts + [silence_path]):
                p.unlink()
            return out_wav
    except Exception as e:
        logging.error(f"Error en la s√≠ntesis XTTS: {e}")
    return None

# (Opcional: si usas main() standalone, lo puedes dejar; si no, elim√≠nalo)
def main():
    SEL_FILE = STATE / "next_release.json"
    if not SEL_FILE.exists():
        raise SystemExit("Falta next_release.json.")

    sel = json.loads(SEL_FILE.read_text(encoding="utf-8"))
    tmdb_id = sel.get("tmdb_id", "unknown")
    title = sel.get("titulo") or sel.get("title") or ""
    slug = slugify(title)  # Asumiendo que slugify est√° definido en otro lado

    narracion, voice_path = generate_narration(sel, tmdb_id, slug)
    return narracion, voice_path

if __name__ == "__main__":
    main()