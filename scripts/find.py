# scripts/find.py
import logging
import json
from pathlib import Path
from datetime import datetime, timezone, timedelta
from googleapiclient.discovery import build
import google.generativeai as genai
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from gemini_config import GEMINI_MODEL
import os
import sys

# --- Imports de utils ---
if str(Path(__file__).resolve().parent) not in sys.path:
    sys.path.insert(0, str(Path(__file__).resolve().parent))

from movie_utils import (
    _load_state, is_published, api_get, get_synopsis_chain, enrich_movie_basic,
    load_config, get_deep_research_data
)

# --- Configuraci√≥n ---
ROOT = Path(__file__).resolve().parents[1]
STATE_DIR = ROOT / "output" / "state"
STATE_DIR.mkdir(parents=True, exist_ok=True)
NEXT_FILE = STATE_DIR / "next_release.json"

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def find_and_select_next():
    config = load_config()
    if not config: return None

    logging.info("üîé INICIANDO B√öSQUEDA DE PEL√çCULA (MODO H√çBRIDO + ANTI-BOLLYWOOD)...")

    # --- YouTube Service ---
    TOKEN_FILE = STATE_DIR / "youtube_token.json"
    if not TOKEN_FILE.exists():
        logging.error("Falta youtube_token.json")
        return None

    try:
        with open(TOKEN_FILE, 'r') as f: token_data = json.load(f)
        creds = Credentials(token=token_data['token'], refresh_token=token_data['refresh_token'],
                            token_uri=token_data['token_uri'], client_id=token_data['client_id'],
                            client_secret=token_data['client_secret'], scopes=token_data['scopes'])
        if creds.expired and creds.refresh_token: creds.refresh(Request())
        youtube = build('youtube', 'v3', credentials=creds)
    except Exception as e:
        logging.error(f"Error auth YouTube: {e}")
        return None

    # --- Paso 1: YouTube Search ---
    try:
        queries = [
            "official movie trailer 2025 new this week",
            "netflix official movie trailer 2025",
            "prime video official movie trailer 2025",
            "disney plus official movie trailer 2025",
            "max hbo official movie trailer 2025",
            "apple tv official movie trailer 2025"
        ]
        
        start_date = (datetime.now(timezone.utc) - timedelta(days=14)).strftime('%Y-%m-%dT%H:%M:%SZ')
        logging.info(f"üì° Buscando estrenos y novedades streaming desde {start_date}...")
        
        all_items = []
        seen_ids = set()

        for q in queries:
            logging.info(f"   > Consultando: '{q}'...")
            next_page = None
            for i in range(2): 
                req = youtube.search().list(part="id,snippet", q=q, type="video", maxResults=50, 
                                            order="relevance", pageToken=next_page, publishedAfter=start_date)
                resp = req.execute()
                items = resp.get("items", [])
                
                for item in items:
                    vid = item['id']['videoId']
                    if vid not in seen_ids:
                        seen_ids.add(vid)
                        all_items.append(item)
                
                next_page = resp.get('nextPageToken')
                if not next_page: break
        
        logging.info(f"üì• Total v√≠deos √∫nicos encontrados: {len(all_items)}")

        videos = []
        video_ids = [item['id']['videoId'] for item in all_items]
        
        # Batch stats
        stats_dict = {}
        for i in range(0, len(video_ids), 50):
            chunk = video_ids[i:i+50]
            if not chunk: continue
            s_resp = youtube.videos().list(part="statistics", id=','.join(chunk)).execute()
            for item in s_resp.get('items', []):
                stats_dict[item['id']] = int(item['statistics'].get('viewCount', 0))

        for item in all_items:
            vid = item['id']['videoId']
            videos.append({
                'title': item['snippet']['title'],
                'videoId': vid,
                'upload_date': item['snippet']['publishedAt'],
                'url': f"https://www.youtube.com/watch?v={vid}",
                'views': stats_dict.get(vid, 0)
            })

    except Exception as e:
        logging.error(f"Error API YouTube: {e}")
        return None

    # --- Paso 2: Filtros Anti-Serie ---
    banned_words = [
        "season", "temporada", "series", "episode", "capitulo", "cap√≠tulo", "vol.", "part 2",
        "hindi", "dubbed", "fan made", "concept trailer", "un-official", "parody",
        "tamil", "telugu", "kannada", "malayalam" # Bloqueo regional extra
    ]
    filtered = []
    for v in videos:
        t = v['title'].lower()
        if 'official' in t and 'trailer' in t:
            if not any(bw in t for bw in banned_words):
                filtered.append(v)
    
    logging.info(f"üîç Filtrado (Anti-Series): Quedan {len(filtered)} candidatos.")
    if not filtered: return None

    # --- Paso 3: Gemini Filter ---
    try:
        genai.configure(api_key=config["GEMINI_API_KEY"])
        model = genai.GenerativeModel(GEMINI_MODEL)
        
        top_candidates = filtered[:120]
        titles_str = "\n".join(f"{i+1}. {v['title']}" for i, v in enumerate(top_candidates)) 
        
        logging.info(f"ü§ñ Enviando {len(top_candidates)} t√≠tulos a Gemini...")
        
        prompt = f"""Analiza estos v√≠deos. Extrae solo PEL√çCULAS (Feature Films) de 2025+. 
        EXCLUYE: Series, TV Shows.
        JSON array: [{{'pelicula': str, 'a√±o': int, 'index': int, 'plataforma': str (opcional)}}]
        List:\n{titles_str}"""
        
        resp = model.generate_content(prompt)
        ai_movies = json.loads(resp.text.strip().lstrip("```json").rstrip("```").strip())
        
        candidates = []
        for am in ai_movies:
            idx = am.get('index', 0) - 1
            if 0 <= idx < len(filtered):
                v = filtered[idx]
                candidates.append({
                    **am, 
                    'trailer_url': v['url'], 
                    'views': v['views'], 
                    'upload_date': v['upload_date'],
                    'video_title_orig': v['title']
                })
    except Exception as e:
        logging.error(f"Error Gemini Filter: {e}")
        return None

    # --- Paso 4: TMDB Enrich & Filtros Estrictos ---
    logging.info("üìö Validando con L√≥gica H√≠brida (Cine vs Streaming)...")
    enriched = []
    
    streaming_keywords = ["netflix", "prime video", "disney", "hbo", "max", "apple tv", "hulu", "peacock"]
    # Lista negra de idiomas (Hindi, Telugu, Tamil, Malayalam, Kannada, Punjabi, Urdu)
    excluded_langs = ['hi', 'te', 'ta', 'ml', 'kn', 'pa', 'ur']

    for cand in candidates:
        movie_name = cand['pelicula']
        
        res = api_get("/search/movie", {"query": movie_name})
        if not res or not res.get("results"): 
            logging.info(f"   [x] TMDB: No encontrado '{movie_name}'")
            continue
        
        tmdb_movie = res["results"][0]
        tmdb_year = str(tmdb_movie.get("release_date", "")[:4])
        
        # 1. Check A√ëO (Flexible +-1)
        target_years = [str(cand['a√±o']-1), str(cand['a√±o']), str(cand['a√±o']+1)]
        if tmdb_year not in target_years: 
            logging.info(f"   [x] Descartado '{movie_name}': A√±o incorrecto ({tmdb_year} vs {target_years})")
            continue
        
        # 2. NUEVO: Check IDIOMA (Anti-Mercado Indio)
        orig_lang = tmdb_movie.get("original_language", "en")
        if orig_lang in excluded_langs:
             logging.info(f"   [x] Descartado '{movie_name}': Mercado Indio/Asi√°tico ({orig_lang})")
             continue

        # 3. Check PUBLICADO
        if is_published(tmdb_movie["id"]): 
            logging.info(f"   [x] Descartado '{movie_name}': YA PUBLICADO.")
            continue
        
        data = enrich_movie_basic(tmdb_movie["id"], movie_name, cand['a√±o'], cand['trailer_url'])
        
        if data and data.get('has_poster'):
            # 4. Check ANTIG√úEDAD (Cine 14d vs Streaming 150d)
            is_streaming = False
            video_title_lower = cand.get('video_title_orig', '').lower()
            ia_plat = cand.get('plataforma', 'Cine')
            
            if ia_plat != 'Cine' or any(k in video_title_lower for k in streaming_keywords):
                is_streaming = True
                data['ia_platform_from_title'] = ia_plat if ia_plat != 'Cine' else "Streaming"

            # Si es streaming, permitimos hasta 1 a√±o (re-estreno en plataforma). Cine: 60 d√≠as.
            days_limit = 365 if is_streaming else 60
            
            if data.get('fecha_estreno'):
                try:
                    release_date = datetime.strptime(data['fecha_estreno'], "%Y-%m-%d")
                    age_days = (datetime.now() - release_date).days
                    
                    if age_days > days_limit:
                        # Excepci√≥n: Si es streaming y el trailer es MUY reciente (<7 d√≠as), lo aceptamos igual
                        # asumiendo que es un lanzamiento en plataforma de una peli vieja.
                        trailer_date = datetime.strptime(cand['upload_date'], "%Y-%m-%dT%H:%M:%SZ")
                        trailer_age = (datetime.now() - trailer_date).days
                        
                        # Validar disponibilidad en Espa√±a para Netflix, Prime, Disney+
                        streaming_platforms = data.get('platforms', {}).get('streaming', [])
                        target_platforms = ["Netflix", "Amazon Prime Video", "Disney Plus"]
                        is_available_es = any(p in sp for sp in streaming_platforms for p in target_platforms if "(US)" not in sp)

                        if is_streaming and trailer_age <= 7 and is_available_es:
                             logging.info(f"   [!] Aceptado '{movie_name}' (Streaming ES): Estreno antiguo ({age_days}d) pero trailer NUEVO ({trailer_age}d) y disponible en Espa√±a.")
                        else:
                            type_str = "Streaming" if is_streaming else "Cine"
                            logging.info(f"   [x] Descartado '{movie_name}': {type_str} antiguo ({age_days} d√≠as > {days_limit}) o no disponible en ES.")
                            continue
                except: pass
            
            # --- Aprobado ---
            data['views'] = cand['views']
            data['upload_date'] = cand['upload_date']
            data['needs_web'] = not bool(data.get('sinopsis'))
            enriched.append(data)
            logging.info(f"   [V] CANDIDATO V√ÅLIDO ({'Streaming üì∫' if is_streaming else 'Cine üé¨'}): {movie_name}")
        else:
            logging.info(f"   [x] Descartado '{movie_name}': Sin datos b√°sicos.")

    if not enriched: 
        logging.info("‚ùå No se encontraron candidatos v√°lidos.")
        return None

    # --- Paso 5: Selecci√≥n (Prioridad Inmediatez) ---
    def calculate_score(item):
        views = item.get('views', 0)
        try:
            pub_time = datetime.strptime(item['upload_date'], "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc)
            hours_ago = (datetime.now(timezone.utc) - pub_time).total_seconds() / 3600
            # Bonus x10 si es de las √∫ltimas 24h
            recency_bonus = 10 if hours_ago < 24 else 1
            return views * recency_bonus
        except:
            return views

    enriched.sort(key=calculate_score, reverse=True)
    selected = enriched[0]

    # --- DEEP RESEARCH ---
    logging.info(f"üïµÔ∏è  Deep Research para: {selected['titulo']}...")
    main_actor_ref = selected.get('actors', [selected['titulo']])[0]
    deep_data = get_deep_research_data(selected['titulo'], selected['fecha_estreno'][:4], main_actor_ref, selected['tmdb_id'])

    if deep_data:
        strategy = deep_data.get('hook_angle', 'CURIOSITY')
        logging.info("\n" + "‚ñà"*60)
        logging.info(f"üß† ESTRATEGIA: {strategy}")
        logging.info(f"ü§´ Salseo: {deep_data.get('movie_curiosity', 'N/A')}")
        logging.info("-" * 60 + "\n")
        
        if deep_data.get('synopsis'): selected['sinopsis'] = deep_data['synopsis']
        if deep_data.get('platform'): selected['ia_platform_from_title'] = deep_data['platform']
        selected['actor_reference'] = deep_data.get('actor_reference')
        selected['director'] = deep_data.get('director')
        selected['movie_curiosity'] = deep_data.get('movie_curiosity')
        selected['hook_angle'] = strategy
    elif selected.get('needs_web'):
        selected['sinopsis'] = get_synopsis_chain(selected['titulo'], 2025, selected['tmdb_id'])
        selected['hook_angle'] = 'PLOT'

    # --- RESUMEN FINAL ---
    logging.info("\n" + "‚ïê"*60)
    logging.info(f"üé¨ RESUMEN DE SELECCI√ìN: {selected['titulo']} ({selected['fecha_estreno'][:4]})")
    logging.info(f"üîó Trailer: {selected.get('trailer_url', 'N/A')}")
    logging.info(f"üß† Estrategia: {selected.get('hook_angle', 'N/A')}")
    logging.info(f"ü§´ Salseo: {selected.get('movie_curiosity', 'N/A')}")
    logging.info(f"üìù Sinopsis: {selected.get('sinopsis', 'N/A')}")
    logging.info("‚ïê"*60 + "\n")

    payload = {**selected, "seleccion_generada": datetime.now(timezone.utc).isoformat() + "Z"}
    NEXT_FILE.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    logging.info(f"‚úÖ SELECCIONADA: {selected['titulo']}")
    return payload

if __name__ == "__main__":
    find_and_select_next()